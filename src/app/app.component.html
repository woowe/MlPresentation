<ml-slideshow>
  <ml-slide data-slide="1">
    <ml-dots></ml-dots>
    <h3>What is</h3>
    <ml-text-to-svg text="MACHINE    LEARNING" fontPath="../assets/fonts/Monoton/Monoton-Regular.ttf"></ml-text-to-svg>
    <!--<h1 ml-title>Machine&nbsp;&nbsp;&nbsp;&nbsp;Learning</h1>-->
    <p>Presented by Jason Cardinal</p>
  </ml-slide>
  <ml-slide data-slide="2" data-main-theme>
    <h3 ml-title>Machine&nbsp;&nbsp;&nbsp;&nbsp;Learning</h3>
    <h2>Definition:</h2>
    <h4><em>the ability for computers to <b>learn</b> without being <b>explicity</b> programmed</em></h4>
  </ml-slide>
  <ml-slide data-slide="3" data-main-theme>
    <h3 ml-title>Machine&nbsp;&nbsp;&nbsp;&nbsp;Learning</h3>
    <h2>How do you teach a computer to learn?</h2>
    <h4>There are a few ways to can teach a computer to learn</h4>
    <ul>
      <li>Reinforcement learning</li>
      <li>Unsupervised learning</li>
      <li>**Supervised learning**</li>
    </ul>
  </ml-slide>
  <ml-slide data-slide="4" data-main-theme>
    <h3 ml-title>Machine&nbsp;&nbsp;&nbsp;&nbsp;Learning</h3>
    <h2>Reinforcement learning</h2>
    <h3>The machine is exposed to an environment where it trains itself continually using trial and error.<br>This machine learns from past experience and tries to capture the best possible knowledge to make accurate business decisions.</h3>
  </ml-slide>
  <ml-slide data-slide="5" data-main-theme>
    <h3 ml-title>Machine&nbsp;&nbsp;&nbsp;&nbsp;Learning</h3>
    <h2>Unsupervised learning</h2>
    <h3>This is where the model is left on its own to determine structure out of data.</h3>
  </ml-slide>
  <ml-slide data-slide="6" data-main-theme>
    <h3 ml-title>Machine&nbsp;&nbsp;&nbsp;&nbsp;Learning</h3>
    <h2>Supervised learning</h2>
    <h3>Where the model is feed a dataset that has both the features and the correct predictions on the feauters.</h3>
    <h3>This is the most common form of training a machine learning model, and what we will focus on today.</h3>
  </ml-slide>
  <ml-slide data-slide="7" data-main-theme>
    <h3 ml-title>Machine&nbsp;&nbsp;&nbsp;&nbsp;Learning</h3>
    <h2>Types of machine learning models (not an exhasived list):</h2>
    <ul>
      <li>Linear Regression</li>
      <li>Logistic Regression</li>
      <li>Decision Tree</li>
      <li>SVM</li>
      <li>KNN</li>
      <li>K-Means</li>
      <li>Random Forest</li>
      <li>**Neural Networks**</li>
    </ul>
  </ml-slide>
  <ml-slide data-slide="8" data-main-theme>
    <h3 ml-title>Machine&nbsp;&nbsp;&nbsp;&nbsp;Learning</h3>
    <h2>What neural networks are:</h2>
    <h3>Neural networks are models that are inspired by the human brain.</h3>
    <h3>They consist of several layers of "neurons", each neuron having an associated activation function with it.</h3>
  </ml-slide>
  <ml-slide data-slide="9" data-main-theme>
    <h3 ml-title>Machine&nbsp;&nbsp;&nbsp;&nbsp;Learning</h3>
    <h2>Types of neural networks (not an exhasived list):</h2>
    <ul>
      <li>Long / Short Term Memory</li>
      <li>Auto Encoder</li>
      <li>Recurrent</li>
      <li>Convolutional</li>
      <li>Neural Turing Machine</li>
      <li>Differential Neural Computer</li>
      <li>**Fully connected**</li>
    </ul>
  </ml-slide>
  <ml-slide data-slide="10" data-main-theme>
    <h3 ml-title>Machine&nbsp;&nbsp;&nbsp;&nbsp;Learning</h3>
    <h2>Fully connected neural network</h2>
    <h3>Probably the simplest multi layered neural network.</h3>
    <h3>This neural network is where all of the neurons in a layer are connected to ever neuron in the layer after it.</h3>
  </ml-slide>
  <ml-slide data-slide="11" data-main-theme>
    <h3 ml-title>Machine&nbsp;&nbsp;&nbsp;&nbsp;Learning</h3>
    <h2>Phases of the neural network</h2>
    <ul>
      <li>Prediction</li>
      <li>Training</li>
    </ul>
  </ml-slide>
  <ml-slide data-slide="12" data-main-theme>
    <h3 ml-title>Machine&nbsp;&nbsp;&nbsp;&nbsp;Learning</h3>
    <h2>Prediction (feed forward)</h2>
    <h3>The most straight forward phase of a neural network.</h3>
    <h3>Basically, you have features that you feed into the neural network.</h3>
    <h3>Based on how each neuron is weighted, the features will flow through the network, get transformed in such a way that it may (or may not) be the correct prediction at the end.</h3>
  </ml-slide>
  <ml-slide data-slide="13" data-main-theme>
    <h3 ml-title>Machine&nbsp;&nbsp;&nbsp;&nbsp;Learning</h3>
    <h2>Training (back propagation)</h2>
    <h3>This is where the magic, or rather the learning, of the model is, unfortunately it is also the most complicated.</h3>
    <h3>
      The first thing to do in order to learn you first have to figure out what you did wrong.<br>
      This is done by defining a loss function. This loss function will give you a way to numerically describe what you did wrong, represented in the difference between the prediction and the ground truth.<br>
      After you have figured out what you have done wrong, you need to go back into you neural network and figure out what neurons where most responsible for the error in your prediction.<br>
      The way to figure out the proper way to adjust these neurons and the weights they carry is to preform Gradient Descent.<br>
      After Gradient Descent has been preformed, your model should be adjusted to make better predictions. Gradient Descent happens in iterations meaning that your model will be able to produce better and better predicitions up until your Gradient Descent algorithm reaches a minima (local or global).
    </h3>
  </ml-slide>
  <ml-slide data-slide="14" data-main-theme>
    <h3 ml-title>Machine&nbsp;&nbsp;&nbsp;&nbsp;Learning</h3>
    <h2>Gradient Descent</h2>
    <h3>
      This is how the model actually learns. It is done by taking the derivative of each neuron's weight w.r.t the loss funciton.<br>
      The derivative of a function returns the slope of a tangent line at a certain point (in this case, the neuron).<br>
      Taking the negative of this slope times some learning rate you define and applying it to the neuron's weight means that you are effectively lowering the error your next prediction will have.
    </h3>
  </ml-slide>
  <ml-slide data-slide="15" data-main-theme>
    <h3 ml-title>Machine&nbsp;&nbsp;&nbsp;&nbsp;Learning</h3>
    <h2>Hyper Parameters</h2>
    <h3>
      Hyper paramenters are the features of your neural network.<br>
      These include:
    </h3>
    <ul>
      <li>Input features</li>
      <li>Number of hidden layers</li>
      <li>Number of neurons in hidden layers</li>
      <li>Number of outputs</li>
      <li>Type of regularization</li>
      <li>Regularization rate</li>
      <li>Type of gradient descent algoritm</li>
      <li>Learning rate</li>
      <li>Batch size</li>
    </ul>
  </ml-slide>
  <ml-slide data-slide="16" data-main-theme>
    <h3 ml-title>Machine&nbsp;&nbsp;&nbsp;&nbsp;Learning</h3>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/rAbhypxs1qQ" frameborder="0" allowfullscreen></iframe>
  </ml-slide>
  <ml-slide data-slide="17" data-main-theme>
    <h3 ml-title>Machine&nbsp;&nbsp;&nbsp;&nbsp;Learning</h3>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/D4C1dB9UheQ" frameborder="0" allowfullscreen></iframe>
  </ml-slide>
  <ml-slide data-slide="1">
    <ml-dots></ml-dots>
    <h3 ml-title>FIN</h3>
  </ml-slide>
</ml-slideshow>
